{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c24595-4818-4891-a111-0f09170a1c09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.40.0 in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (4.40.0)\n",
      "Requirement already satisfied: filelock in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (from transformers==4.40.0) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (from transformers==4.40.0) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (from transformers==4.40.0) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/tljh/user/lib/python3.12/site-packages (from transformers==4.40.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/tljh/user/lib/python3.12/site-packages (from transformers==4.40.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (from transformers==4.40.0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /opt/tljh/user/lib/python3.12/site-packages (from transformers==4.40.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (from transformers==4.40.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (from transformers==4.40.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/tljh/user/lib/python3.12/site-packages (from transformers==4.40.0) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/tljh/user/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jupyter-nafisha/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from requests->transformers==4.40.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.12/site-packages (from requests->transformers==4.40.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.12/site-packages (from requests->transformers==4.40.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from requests->transformers==4.40.0) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c0d71b-ea3a-47e5-94e2-29afc13641ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "from transformers import AutoConfig, AutoModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ba4376-e4e7-4e4d-b525-2a948db13915",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = '/home/jupyter-nafisha/X-ray/Inference_data/Chexpert/patient00314/study8/view1_frontal.jpg'  \n",
    "CHECKPOINT = \"/home/common/checkpoints/stage3_best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7cda2b-73c1-4700-ad40-affd561f20ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = T.Compose([\n",
    "    T.Resize((512, 512), interpolation=T.InterpolationMode.BICUBIC),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.48145466, 0.4578275,  0.40821073],\n",
    "        std =[0.26862954, 0.26130258, 0.27577711]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff7cb3f-de6c-415b-b401-dabebb73c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/jupyter-nafisha/X-ray/Nikita.csv\")\n",
    "label_cols = df.columns.tolist()[1:]    # [\"Atelectasis\", ..., \"Pleural Effusion\"]\n",
    "num_labels = len(label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd50744d-5f6e-4ad1-909c-7429c5283018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CXRMultiLabel(nn.Module):\n",
    "    def __init__(self, vision_model, num_labels, pos_weight):\n",
    "        super().__init__()\n",
    "        self.vision = vision_model\n",
    "        in_dim = vision_model.config.hidden_size\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_labels)\n",
    "        )\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        out = self.vision(pixel_values=pixel_values, return_dict=True)\n",
    "        cls = out.last_hidden_state[:, 0, :]\n",
    "        logits = self.head(cls)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c944abe-ca67-4d8d-9898-f41b2752a81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-nafisha/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vision_cfg = AutoConfig.from_pretrained(\n",
    "    \"StanfordAIMI/XraySigLIP__vit-l-16-siglip-384__webli\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "vision_full = AutoModel.from_pretrained(\n",
    "    \"StanfordAIMI/XraySigLIP__vit-l-16-siglip-384__webli\",\n",
    "    config=vision_cfg,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "vision_encoder = vision_full.vision_model\n",
    "del vision_full\n",
    "\n",
    "pos_weight = torch.ones(num_labels)   # NOT used during inference\n",
    "\n",
    "model = CXRMultiLabel(\n",
    "    vision_model=vision_encoder,\n",
    "    num_labels=num_labels,\n",
    "    pos_weight=pos_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990ddd21-3db8-44ac-8392-64cb6c118366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CXRMultiLabel(\n",
       "  (vision): SiglipVisionTransformer(\n",
       "    (embeddings): SiglipVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16), padding=valid)\n",
       "      (position_embedding): Embedding(1024, 1024)\n",
       "    )\n",
       "    (encoder): SiglipEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x SiglipEncoderLayer(\n",
       "          (self_attn): SiglipAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SiglipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): SiglipMultiheadAttentionPoolingHead(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (layernorm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): SiglipMLP(\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(CHECKPOINT, map_location=\"cpu\", weights_only= False)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd16a77-fbb2-404c-bb69-a7c71cab6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab90f292-b549-475c-b254-285d6659343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_single_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    pv = preprocess(img).unsqueeze(0)     # [1,3,512,512]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(pv)\n",
    "        probs  = sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Return label â†’ (probability, prediction)\n",
    "    results = { label_cols[i]: (float(probs[i]), int(preds[i])) for i in range(num_labels) }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc739ac5-1f2b-42f0-82de-237e97f1032f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter-nafisha/X-ray'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd1ff0fb-0537-45f1-b338-b5a6659656aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_path= '/home/jupyter-nafisha/X-ray/CSVs/test.csv'\n",
    "test_data= pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5a12e4d-2653-4bfa-9f25-de8a4d5b0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/jupyter-nafisha/X-ray/Data'\n",
    "\n",
    "records = []\n",
    "\n",
    "count=0\n",
    "\n",
    "for idx, row in test_data.iterrows():\n",
    "    file_path = os.path.join(data_dir, row['image_id'])\n",
    "    # output = {}\n",
    "    output = infer_single_image(file_path)\n",
    "    \n",
    "    diseases = []\n",
    "    for disease, (prob, pred) in output.items():\n",
    "        if prob > 0.5:\n",
    "            diseases.append(disease)\n",
    "    \n",
    "    class_name = \", \".join(diseases) if diseases else \"No FInding\"\n",
    "    \n",
    "    records.append({\n",
    "        \"image_id\": row[\"image_id\"],\n",
    "        \"class_name\": class_name\n",
    "    })\n",
    "\n",
    "    count+=1\n",
    "\n",
    "    if count==5:\n",
    "        break\n",
    "\n",
    "# Create the new dataframe\n",
    "new_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf8bd821-7e02-4813-be18-3ff00c77b995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.pth   \u001b[0m\u001b[01;34mData\u001b[0m/            Nikita.csv      test_predictions.csv\n",
      "\u001b[01;34mcheckpoints\u001b[0m/     dataset.py       predict.py      train.py\n",
      "chexAgent.ipynb  \u001b[01;34mInference_data\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/    transforms.py\n",
      "CSV.ipynb        last_model.pth   stage3_best.pt  utils.py\n",
      "\u001b[01;34mCSVs\u001b[0m/            model.py         Testing.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687e655-30f7-42ac-b6b2-a84ad038eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('/home/jupyter-nafisha/X-ray/CSVs/chexAgent_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
